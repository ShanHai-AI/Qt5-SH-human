<!--
 * @Descripttion: 
 * @version: 
 * @Author: LiQiang
 * @Date: 2022-09-29 19:46:49
 * @LastEditTime: 2022-09-29 19:58:27
-->
# 多人姿态估计

## 快速开始
安装[Sh-human](https://github.com/ShanHai-AI/SH-human)后,执行以下命令
```dotnetcli
python track+pose.py --source 0 --show-vid
```
--source 为输入视频的路径，0代表本地摄像头

--show-vid 为是否可视化展示

其他参数可以参考[track+pose.py](https://github.com/ShanHai-AI/SH-human/blob/main/track%2Bpose.py)


## 算法流程
我们在track+pose.py文件中调用了关键点估计所用的hook，具体在hook/skeleton_pose.py文件中，调用了mmpose框架，使用了轻量级的`mmpose/configs/body/2d_kpt_sview_rgb_img/topdown_heatmap/coco/shufflenetv2_coco_256x192.py` ,达到高精度，快速度的效果。此外每个骨架信息返回**track_id**,可以将每个人的关节点信息分开。